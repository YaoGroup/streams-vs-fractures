{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75dfd8de-a66b-4c1f-a1bf-dac29bfa0713",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd71dde5-0933-4902-b763-7c9bfbecf117",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# FD_simple_CNN_ncwork_float32\n",
    "# CNN code for image_data which is stored as float32\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ecb9f0-ab48-463e-bdb4-6cf749e97720",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# IMPORTS\n",
    "###############################\n",
    "\n",
    "# torch things\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import Sampler\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "# netCDF4 things\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset as ncDataset\n",
    "import xarray as xr\n",
    "\n",
    "# normal python things\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37aea6d-8187-4d0d-8e1d-d243c462eafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "hyperparameters set\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 294, 294]              40\n",
      "         MaxPool2d-2          [-1, 4, 147, 147]               0\n",
      "            Conv2d-3          [-1, 8, 147, 147]             296\n",
      "         MaxPool2d-4            [-1, 8, 73, 73]               0\n",
      "            Conv2d-5           [-1, 16, 73, 73]           1,168\n",
      "         MaxPool2d-6           [-1, 16, 36, 36]               0\n",
      "            Conv2d-7           [-1, 32, 36, 36]           4,640\n",
      "         MaxPool2d-8           [-1, 32, 18, 18]               0\n",
      "            Conv2d-9           [-1, 64, 18, 18]          18,496\n",
      "        MaxPool2d-10             [-1, 64, 9, 9]               0\n",
      "           Conv2d-11            [-1, 128, 9, 9]          73,856\n",
      "        MaxPool2d-12            [-1, 128, 4, 4]               0\n",
      "           Linear-13                    [-1, 1]           2,049\n",
      "================================================================\n",
      "Total params: 100,545\n",
      "Trainable params: 100,545\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.33\n",
      "Forward/backward pass size (MB): 6.44\n",
      "Params size (MB): 0.38\n",
      "Estimated Total Size (MB): 7.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# CNN ARCHITECTURE\n",
    "###############################\n",
    "\n",
    "# Create simple CNN architecture\n",
    "class tinyCNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_features):\n",
    "        super(tinyCNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels=4, kernel_size=(3,3), stride=(1,1), padding=(1,1)) # same convolution, meaning that the output size will be the same dimensions as the input (294x294) here\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=(3,3), stride=(1,1), padding=(1,1)) # same convolution, meaning that the output size will be the same dimensions as the input (294x294) here\n",
    "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.conv4 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.conv5 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.conv6 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.fc1 = nn.Linear(128*4*4, out_features) # size should be (out_channels from previous layer)*(input_size/2^num_layers) because the max pooling reduces dimension by 2 fold in each layer\n",
    "        # self.softplus = nn.Softplus()  # Define Softplus as a layer\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0],-1) # flattens to be able to put into the fully-connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = torch.abs(x)  # Ensure no negative values in the output (do EITHER this or softplus, not both)\n",
    "        # x = self.softplus(x) # Ensure no negative values in output (do EITHER this or abs, not both)\n",
    "\n",
    "        return x\n",
    "    \n",
    "###############################\n",
    "# SET GPU AND HYPERPARAMETERS\n",
    "###############################\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Hyperparameters\n",
    "in_channels = 1\n",
    "out_features = 1\n",
    "learning_rate = 0.001\n",
    "batch_size = 512\n",
    "num_epochs = 100\n",
    "input_size = (1,294,294) #[C, H, W], the np arrays of images are [H, W], and the transform function converts to [H, W, C] \n",
    "\n",
    "# network structure\n",
    "# in_channels = [\n",
    "\n",
    "print(\"hyperparameters set\")\n",
    "\n",
    "###############################\n",
    "# INITIALIZE NETWORK\n",
    "###############################\n",
    "\n",
    "# Initialize network\n",
    "model = tinyCNN(in_channels, out_features).to(device)\n",
    "\n",
    "# Print the model summary\n",
    "summary(model, input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b35812c-bff2-4f75-bb37-9057c9261310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'fracture_density' ()> Size: 8B\n",
      "array(0.45724004)\n",
      "<xarray.DataArray 'fracture_density' ()> Size: 8B\n",
      "array(0.)\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# TRANSFORMATION DEFINITIONS\n",
    "###############################\n",
    "\n",
    "# define the desired transformations to the images and the labels (transform, transform_label)\n",
    "\n",
    "# transform: transforms images from numpy array of shape [H, W] to tensors of shape [C, H, W] in range [0, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Converts images to PyTorch tensors and scales to [0, 1]\n",
    "])\n",
    "\n",
    "\n",
    "# # transform_label: transforms the labels to a more normal distribution\n",
    "# def transform_label_function(label):\n",
    "#     # Ensure label is a tensor\n",
    "#     label_tensor = torch.tensor(label, dtype=torch.float32)\n",
    "#     # Apply the transformation\n",
    "#     transformed_label = (torch.log10(label_tensor + 0.001) + 2)\n",
    "#     return transformed_label\n",
    "\n",
    "# transform_label: transforms the labels to be between [0,1]\n",
    "fracture_density_max = xr.open_dataset('data/data/orig_nc_files/ncfile_comb_north.nc')['fracture_density'].max()\n",
    "fracture_density_min = xr.open_dataset('data/data/orig_nc_files/ncfile_comb_north.nc')['fracture_density'].min()\n",
    "print(fracture_density_max)\n",
    "print(fracture_density_min)\n",
    "def transform_label_function(label):\n",
    "    # Ensure label is a tensor\n",
    "    label_tensor = torch.tensor(label, dtype=torch.float32)\n",
    "    # Apply the transformation\n",
    "    transformed_label = torch.tensor(((label_tensor-fracture_density_min) / (fracture_density_max-fracture_density_min)).values, dtype=torch.float32)\n",
    "    return transformed_label\n",
    "\n",
    "# inverse transform (to get back to original fracture density after the training)\n",
    "# be careful to make sure this is the inverse function to the transform function (manual)\n",
    "# def inverse_transform_label_function(transformed_label):\n",
    "#     inverse_transformed_label = 10**(transformed_label-2) - 0.001\n",
    "#     return inverse_transformed_label\n",
    "\n",
    "# inverse transform for between [0,1] transform\n",
    "def inverse_transform_label_function(transformed_label):\n",
    "    inverse_transformed_label = torch.tensor(((transformed_label*((fracture_density_max-fracture_density_min))) - fracture_density_min).values, dtype=torch.float32)\n",
    "    return inverse_transformed_label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a23d7-168c-49a4-9ebc-dd1a8d4c2b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #################################################################\n",
    "# # # TO LOOK AT THE LABELS AND TRANSFORMED LABELS IN THE DATASET\n",
    "# # #################################################################\n",
    "\n",
    "# # extract original labels:\n",
    "# nc_data = ncDataset('data/data/ncfile_south_combined.nc', 'r')\n",
    "# original_labels = nc_data.variables['fracture_density'][:].astype(np.float32)\n",
    "\n",
    "# # Compute transformed labels\n",
    "# transformed_labels = []\n",
    "# for label in original_labels:\n",
    "#     transformed_label = transform_label_function(label)\n",
    "#     transformed_labels.append(transformed_label)\n",
    "\n",
    "# # Convert list to numpy arrays\n",
    "# transformed_labels = np.array(transformed_labels)\n",
    "\n",
    "# # histogram plots\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# # Histogram of original labels\n",
    "# plt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot\n",
    "# plt.hist(original_labels, bins=200, alpha=0.7, color='blue')\n",
    "# plt.title('Original Labels Distribution')\n",
    "# plt.xlabel('Fracture Density')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.grid(True)\n",
    "\n",
    "# # Histogram of transformed labels\n",
    "# plt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot\n",
    "# plt.hist(transformed_labels, bins=200, alpha=0.7, color='green')\n",
    "# plt.title('Transformed Labels Distribution')\n",
    "# plt.xlabel('Transformed Fracture Density')\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # how many FD=0 are in the dataset:\n",
    "# num_zeros = np.count_nonzero(original_labels == 0)\n",
    "# print(\"Number of zeros in the original label set:\", num_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e001d9-2035-4d9d-bcac-25e25816168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# DATASET CLASS CREATION FROM .nc FILES\n",
    "###############################\n",
    "\n",
    "# create custom dataset class from the .nc files\n",
    "class NCDataset(Dataset):\n",
    "    def __init__(self, nc_file_path, transform=None, transform_label=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            nc_file_path (string): Path to the .nc file\n",
    "            transform (callable, optional): optional transform to apply to images\n",
    "            transform_label (callable, optional): optional transform to apply to the labels\n",
    "        \"\"\"\n",
    "        # load the .nc file\n",
    "        self.nc_data = ncDataset(nc_file_path, 'r')\n",
    "        \n",
    "        # access the images (image_data) and labels (fracture_density) from the .nc file\n",
    "        self.image_data = self.nc_data.variables['image_data']\n",
    "        self.fracture_density = self.nc_data.variables['fracture_density']\n",
    "        \n",
    "        # image and label transforms (transform, transform_label)\n",
    "        self.transform = transform\n",
    "        self.transform_label = transform_label\n",
    "        \n",
    "        # load whole array into memory (could also convert to float32 here if that is not already done in preprocessing)\n",
    "        self.image_data = self.image_data[:,:,:].astype(np.float32)\n",
    "        self.fracture_density = self.fracture_density[:].astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.image_data.shape[2]  # number of images is the third dimension [2]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Extract a single image and its corresponding label\n",
    "        image = self.image_data[:, :, idx]\n",
    "        label = self.fracture_density[idx]\n",
    "        \n",
    "        # Apply image transformation if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # apply label transformation, if any\n",
    "        if self.transform_label:\n",
    "            label = self.transform_label(label)    \n",
    "            \n",
    "        # The image should already be a tensor because of the transform, \n",
    "        # and label needs to be converted only if transform_label does not do it\n",
    "        if not torch.is_tensor(label):\n",
    "            label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        # return\n",
    "        return image, label\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65c8a534-64d7-4bb2-892b-14a0b193a0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders for train and val sets have been set\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# SET THE DATALOADERS (this takes a while when using large dataset)\n",
    "###############################\n",
    "\n",
    "# .nc file path\n",
    "nc_file_path = 'data/data/ncfile_south_outside_train.nc'\n",
    "nc_file_path_val = 'data/data/ncfile_south_outside_val.nc'\n",
    "\n",
    "# load dataset from .nc file using NCDataset\n",
    "# ds_train = NCDataset(nc_file_path, transform=transform, transform_label=lambda x: transform_label_function(x))\n",
    "# ds_val = NCDataset(nc_file_path_val, transform=transform, transform_label=lambda x: transform_label_function(x))\n",
    "ds_train = NCDataset(nc_file_path, transform=transform, transform_label=transform_label_function)\n",
    "ds_val = NCDataset(nc_file_path_val, transform=transform, transform_label=transform_label_function)\n",
    "\n",
    "# set the sampler based on samples <= 0.05 (or some other value)\n",
    "weights = torch.ones(len(ds_train), dtype=torch.float)  # Start with all weights equal to 1\n",
    "zero_label_weight = 0.5  # Weight for zero-labeled samples, adjust as needed\n",
    "labels_train = np.array(nc.Dataset(nc_file_path, 'r').variables['fracture_density']).astype(np.float32) \n",
    "weights[labels_train == 0] = zero_label_weight  # Assign lower weight to zero-labeled samples\n",
    "sampler_zerosreduction = WeightedRandomSampler(weights=weights, num_samples=len(ds_train), replacement=False)\n",
    "\n",
    "# dataloader (NOTE: only use either a sampler or shuffle, not both)\n",
    "dataloader_train = DataLoader(ds_train, batch_size=batch_size, sampler=None, shuffle=True, num_workers=8)\n",
    "dataloader_val = DataLoader(ds_val, batch_size=batch_size, sampler=None, num_workers=8)\n",
    "\n",
    "print(f'DataLoaders for train and val sets have been set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d18a5ae-6095-4f0c-86c8-7f590ffd29b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss criterion and optimizer have been set\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# LOSS, OPTIMIZER\n",
    "###############################\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(f'loss criterion and optimizer have been set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eea08c-85eb-4617-9ddc-640514e663f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = ds_train[0]  # Get the first item\n",
    "print(f\"Label type after fetch: {type(label)}\")  # Check the type directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52665d7c-0a5d-4340-91b2-fa37d5506112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size[5515]; val size[5515]; batch size[128]; batches per epoch[44]\n",
      " epoch[12/100]; train loss[0.00030389]; val loss[0.00437625]; elapsed time[0.8740 mins]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# print(f\"\\r Starting epoch {epoch+1}\")\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# start epoch timer\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     start_time_epoch \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader_train):\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m# print(f\"\\r Processing batch {batch_idx+1}\")\u001b[39;00m\n\u001b[1;32m     25\u001b[0m         \n\u001b[1;32m     26\u001b[0m         \u001b[38;5;66;03m# put data to cuda if possible\u001b[39;00m\n\u001b[1;32m     27\u001b[0m         images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;66;03m# this moves the data tensor to the device which will carry out the computation\u001b[39;00m\n\u001b[1;32m     28\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;66;03m# this moves the target tensor to the device which will carry out the computation\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# TRAINING LOOP\n",
    "###############################\n",
    "\n",
    "losses = []  # List to store loss values\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "best_loss_val = float('inf')  # Initialize with a high value\n",
    "best_loss_train = float('inf')  # Initialize with a high value\n",
    "\n",
    "# beginning of training print statement:\n",
    "print(f'train size[{len(ds_train)}]; val size[{len(ds_val)}]; batch size[{batch_size}]; batches per epoch[{len(dataloader_train)}]')\n",
    "\n",
    "# Now use the DataLoader in the training loop\n",
    "start_time_trainloop = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    # print(f\"\\r Starting epoch {epoch+1}\")\n",
    "    \n",
    "    # start epoch timer\n",
    "    start_time_epoch = time.time() \n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(dataloader_train):\n",
    "        # print(f\"\\r Processing batch {batch_idx+1}\")\n",
    "        \n",
    "        # put data to cuda if possible\n",
    "        images = images.to(device=device) # this moves the data tensor to the device which will carry out the computation\n",
    "        labels = labels.to(device=device) # this moves the target tensor to the device which will carry out the computation\n",
    "        \n",
    "        # forward pass\n",
    "        preds = torch.squeeze(model(images)) # this does the forward pass of the data through the model and computes the model predictions (aka 'scores') for each imput in the batch. scores represents the model prediction for the given input data\n",
    "        # preds = torch.squeeze(preds)  # squeezes dimensions from [64, 1] to [64]. Now preds has shape [64], which is the same shape as the labels \n",
    "        loss = criterion(preds, labels) # this calculates the loss between the model prediction (scores) and the true label value (targets)\n",
    "        # print(f'preds shape[{preds.shape}]')\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad() # sets all gradients to zero at the beginning of each batch, so doesn't store the backprop calculations from previous forward props\n",
    "        loss.backward() # computes the gradients via backprop\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step() # updates the weights depending on the gradients computed in loss.backward\n",
    "\n",
    "        # Record the training loss for each iteration\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    # record the training loss for each epoch\n",
    "    losses_train.append(loss.item())\n",
    "        \n",
    "    # Validation phase (get validation loss and collect labels and predictions)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for images, labels in dataloader_val:\n",
    "            images = images.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            preds = torch.squeeze(model(images))\n",
    "            loss_val = criterion(preds, labels)\n",
    "    losses_val.append(loss_val.item())\n",
    "    \n",
    "    # save loss at the global minimum of the validation loss (loss_val)\n",
    "    if loss_val < best_loss_val:\n",
    "        # Update the best loss value\n",
    "        best_loss_val = loss_val\n",
    "        # Save the best model parameters\n",
    "        bestmodel_val_wts = copy.deepcopy(model.state_dict())\n",
    "        # Optionally, save to a file\n",
    "        torch.save(bestmodel_val_wts, 'bestmodel_wts_val.pt')\n",
    "        \n",
    "    # save loss at the global minimum of the training loss (loss_train)\n",
    "    if loss < best_loss_train:\n",
    "        # Update the best loss value\n",
    "        best_loss_train = loss\n",
    "        # Save the best model parameters\n",
    "        bestmodel_train_wts = copy.deepcopy(model.state_dict())\n",
    "        # Optionally, save to a file\n",
    "        torch.save(bestmodel_train_wts, 'bestmodel_wts_train.pt')\n",
    "        \n",
    "    # end epoch timer\n",
    "    end_time_epoch = time.time()\n",
    "    epoch_duration = end_time_epoch - start_time_epoch\n",
    "    elapsed_time_training = (end_time_epoch-start_time_trainloop)/60 #[minutes]\n",
    "    \n",
    "    # print end-of-epoch statement\n",
    "    sys.stdout.write(f'\\r epoch[{epoch+1}/{num_epochs}]; train loss[{loss.item():.8f}]; val loss[{loss_val.item():.8f}]; time per epoch[{(elapsed_time_training/(epoch+1)):.4f} mins]; elapsed time[{elapsed_time_training:.4f} mins]')\n",
    "\n",
    "    # Save the loss lists\n",
    "    # Convert lists to tensors\n",
    "    train_loss_tensor = torch.tensor(losses_train)\n",
    "    val_loss_tensor = torch.tensor(losses_val)\n",
    "    # Save tensors\n",
    "    torch.save({'train_loss': train_loss_tensor, 'val_loss': val_loss_tensor}, 'losses.pt')\n",
    "    \n",
    "# NOTE: 'targets' means the ground-truth labels, 'scores' or 'preds' are model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43859d36-555d-4822-a760-2bf4b78d6491",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# AFTER THE TRAINING LOOP CONCLUDES:\n",
    "# LOAD THE TRAINED MODEL\n",
    "########################################\n",
    "\n",
    "# After training is complete, you can load the best model weights back into your model\n",
    "model = CNN(in_channels, out_features)\n",
    "weights_path = 'bestmodel_wts_train.pt'\n",
    "model.load_state_dict(torch.load(weights_path)) # load the model state from the desired output file (either best validation model or best training model)\n",
    "model.to(device) # send model to GPU\n",
    "model.eval()  # Evaluate model mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753107d1-54e1-4ff4-8714-4430d6b3cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# AFTER THE TRAINING LOOP CONCLUDES:\n",
    "# GET LABELS AND PREDICTIONS FOR TRAIN AND VAL SETS FROM THE TRAINED MODEL\n",
    "########################################\n",
    "\n",
    "# get labels and predictions for both training set and validation set\n",
    "# training set:\n",
    "model.eval()  # Evaluate mode\n",
    "predictions_train = []\n",
    "actual_labels_train = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_train:  # Assuming you want to do this for the training set\n",
    "        images = images.to(device)\n",
    "        preds = model(images)\n",
    "        predictions_train.extend(preds.view(-1).tolist())  # Flatten and convert to list\n",
    "        actual_labels_train.extend(labels.tolist())\n",
    "# Ensure predictions and actual_labels are numpy arrays for easier manipulation\n",
    "predictions_train = np.array(predictions_train)\n",
    "actual_labels_train = np.array(actual_labels_train)\n",
    "\n",
    "print(f\"train set: predictions and labels acquired ({len(actual_labels_train)})\")\n",
    "    \n",
    "# validation set:\n",
    "model.eval()  # Evaluate mode\n",
    "predictions_val = []\n",
    "actual_labels_val = []\n",
    "with torch.no_grad():\n",
    "    for images_val, labels_val in dataloader_val:  # Assuming you want to do this for the training set\n",
    "        images_val = images_val.to(device)\n",
    "        preds_val = model(images_val)\n",
    "        predictions_val.extend(preds_val.view(-1).tolist())  # Flatten and convert to list\n",
    "        actual_labels_val.extend(labels_val.tolist())\n",
    "# Ensure predictions and actual_labels are numpy arrays for easier manipulation\n",
    "predictions_val = np.array(predictions_val)\n",
    "actual_labels_val = np.array(actual_labels_val)\n",
    "\n",
    "print(f\"validation set: predictions and labels acquired ({len(actual_labels_val)})\")\n",
    "\n",
    "# get the training and validation RMSE (transformed and un-transformed)\n",
    "rmse_train_transf = np.sqrt(np.mean((actual_labels_train - predictions_train) ** 2))\n",
    "rmse_val_transf = np.sqrt(np.mean((actual_labels_val - predictions_val) ** 2))\n",
    "# rmse_train_untransf = np.sqrt(np.mean((inverse_transform_label_function(actual_labels_train, facs=3) - inverse_transform_label_function(predictions_train, facs=3)) ** 2))\n",
    "# rmse_val_untransf = np.sqrt(np.mean((inverse_transform_label_function(actual_labels_val, facs=3) - inverse_transform_label_function(predictions_val, facs=3)) ** 2))\n",
    "\n",
    "# print(f'training set RMSE:\\n rmse_train_transf[{rmse_train_transf:.4f}]\\n rmse_val_transf[{rmse_val_transf:.4f}]\\nvalidation set RMSE: \\n rmse_train_untransf[{rmse_train_untransf:.4f}]\\n rmse_val_untransf[{rmse_val_untransf:.4f}]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7990e5f5-f05b-400d-87f4-2a537adaf76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# PLOTS\n",
    "###############################\n",
    "\n",
    "# plot of training and validation losses across epochs\n",
    "plt.figure()\n",
    "plt.plot(np.asarray(loaded_losses['train_loss']), c='black', label='training loss')\n",
    "plt.plot(np.asarray(loaded_losses['val_loss']), c='red', label='validation loss')\n",
    "plt.legend()\n",
    "plt.title(f'training and validation losses per epoch; {num_epochs} epochs')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "# plt.ylim(0,0.005)\n",
    "\n",
    "# plot of the predictions versus labels for training set and validation set (transformed labels)\n",
    "plt.figure()\n",
    "plt.scatter(actual_labels_train, predictions_train, c='black', s=12, label='train set')\n",
    "# plt.scatter(actual_labels_val, predictions_val, c='red', s=7, label='val set')\n",
    "plt.plot(np.array(np.linspace(-2,2,11)),np.array(np.linspace(-2,2,11)),'b-')\n",
    "plt.title('predictions vs actual labels')\n",
    "plt.xlabel('actual (ground truth) labels')\n",
    "plt.ylabel('predictions (CNN preds)')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "\n",
    "# plot of the predictions versus labels for training set and validation set (original labels)\n",
    "# plt.figure()\n",
    "# plt.scatter(inverse_transform_label_function(actual_labels_train), inverse_transform_label_function(predictions_train), c='black', s=12, label='train set')\n",
    "# # plt.scatter(inverse_transform_label_function(actual_labels_val), inverse_transform_label_function(predictions_val), c='red', s=7, label='val set')\n",
    "# plt.plot(np.array(np.linspace(-2,2,11)),np.array(np.linspace(-2,2,11)),'b-')\n",
    "# plt.title('predictions vs actual labels')\n",
    "# plt.xlabel('actual (ground truth) labels')\n",
    "# plt.ylabel('predictions (CNN preds)')\n",
    "# plt.xlim([0, 0.5])\n",
    "# plt.ylim([0, 0.5])\n",
    "# plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db717355-0c76-4b12-a350-a34d5077fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# PLOT TRAINING LOSS CURVE AT EACH ITERATION\n",
    "###############################\n",
    "\n",
    "# Calculate the total number of batches processed\n",
    "total_batches = len(dataloader_train) * num_epochs\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "plt\n",
    "plt.plot(losses, label='training Loss')\n",
    "\n",
    "# # Add vertical lines for each epoch\n",
    "# for epoch in range(num_epochs):\n",
    "#     # Calculate the iteration index at the end of each epoch\n",
    "#     epoch_end_iter = len(data_loader) * (epoch + 1)\n",
    "#     plt.axvline(x=epoch_end_iter, color='r', linestyle='--', linewidth=1)\n",
    "\n",
    "# plt.ylim(0,0.05)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('training loss as a function of iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d494ed-ab24-4d22-857a-8f21b03980d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
